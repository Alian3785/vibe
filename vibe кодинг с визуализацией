# pip install gymnasium stable-baselines3 numpy wandb

import numpy as np
import gymnasium as gym
from gymnasium import spaces
import random
from operator import itemgetter

# ============================================================
#                      –ò–°–•–û–î–ù–´–ï –î–ê–ù–ù–´–ï
# ============================================================
UNITS_RED = [
    {"–∏–º—è": "—Ä—ã—Ü–∞—Ä—å1",  "–∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–∞": 67, "–∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–∞_–±–∞–∑–∞": 67, "team": "red",  "position": 1, "stand": "ahead",  "Type": "Archer", "–£—Ä–æ–Ω": 20, "–ó–¥–æ—Ä–æ–≤—å–µ": 60},
    {"–∏–º—è": "—Ä—ã—Ü–∞—Ä—å2",  "–∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–∞": 33, "–∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–∞_–±–∞–∑–∞": 33, "team": "red",  "position": 2, "stand": "ahead",  "Type": "Archer", "–£—Ä–æ–Ω": 20, "–ó–¥–æ—Ä–æ–≤—å–µ": 60},
    {"–∏–º—è": "—Ä—ã—Ü–∞—Ä—å3",  "–∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–∞": 78, "–∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–∞_–±–∞–∑–∞": 78, "team": "red",  "position": 3, "stand": "ahead",  "Type": "Archer", "–£—Ä–æ–Ω": 20, "–ó–¥–æ—Ä–æ–≤—å–µ": 60},
    {"–∏–º—è": "—Ä—ã—Ü–∞—Ä—å7",  "–∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–∞": 45, "–∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–∞_–±–∞–∑–∞": 45, "team": "red",  "position": 4, "stand": "behind", "Type": "Archer", "–£—Ä–æ–Ω": 20, "–ó–¥–æ—Ä–æ–≤—å–µ": 60},
    {"–∏–º—è": "—Ä—ã—Ü–∞—Ä—å8",  "–∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–∞": 90, "–∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–∞_–±–∞–∑–∞": 90, "team": "red",  "position": 5, "stand": "behind", "Type": "Archer", "–£—Ä–æ–Ω": 20, "–ó–¥–æ—Ä–æ–≤—å–µ": 60},
    {"–∏–º—è": "—Ä—ã—Ü–∞—Ä—å9",  "–∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–∞": 12, "–∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–∞_–±–∞–∑–∞": 12, "team": "red",  "position": 6, "stand": "behind", "Type": "Archer", "–£—Ä–æ–Ω": 20, "–ó–¥–æ—Ä–æ–≤—å–µ": 60},
]
UNITS_BLUE = [
    {"–∏–º—è": "—Ä—ã—Ü–∞—Ä—å4",  "–∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–∞": 88, "–∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–∞_–±–∞–∑–∞": 88, "team": "blue", "position": 7,  "stand": "ahead",  "Type": "Archer", "–£—Ä–æ–Ω": 20, "–ó–¥–æ—Ä–æ–≤—å–µ": 60},
    {"–∏–º—è": "—Ä—ã—Ü–∞—Ä—å5",  "–∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–∞": 55, "–∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–∞_–±–∞–∑–∞": 55, "team": "blue", "position": 8,  "stand": "ahead",  "Type": "Archer", "–£—Ä–æ–Ω": 20, "–ó–¥–æ—Ä–æ–≤—å–µ": 60},
    {"–∏–º—è": "—Ä—ã—Ü–∞—Ä—å6",  "–∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–∞": 22, "–∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–∞_–±–∞–∑–∞": 22, "team": "blue", "position": 9,  "stand": "ahead",  "Type": "Archer", "–£—Ä–æ–Ω": 20, "–ó–¥–æ—Ä–æ–≤—å–µ": 60},
    {"–∏–º—è": "—Ä—ã—Ü–∞—Ä—å10", "–∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–∞": 60, "–∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–∞_–±–∞–∑–∞": 60, "team": "blue", "position": 10, "stand": "behind", "Type": "Archer", "–£—Ä–æ–Ω": 20, "–ó–¥–æ—Ä–æ–≤—å–µ": 60},
    {"–∏–º—è": "—Ä—ã—Ü–∞—Ä—å11", "–∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–∞": 47, "–∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–∞_–±–∞–∑–∞": 47, "team": "blue", "position": 11, "stand": "behind", "Type": "Archer", "–£—Ä–æ–Ω": 20, "–ó–¥–æ—Ä–æ–≤—å–µ": 60},
    {"–∏–º—è": "—Ä—ã—Ü–∞—Ä—å12", "–∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–∞": 75, "–∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–∞_–±–∞–∑–∞": 75, "team": "blue", "position": 12, "stand": "behind", "Type": "Archer", "–£—Ä–æ–Ω": 20, "–ó–¥–æ—Ä–æ–≤—å–µ": 60},
]

BLUE_POSITIONS = list(range(7, 13))
RED_POSITIONS  = list(range(1, 7))
MAX_HP = 60
MAX_INIT = max([u["–∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–∞_–±–∞–∑–∞"] for u in (UNITS_RED + UNITS_BLUE)])


# ============================================================
#                      –û–ü–†–ï–î–ï–õ–ï–ù–ò–ï –°–†–ï–î–´
# ============================================================

class BattleEnv(gym.Env):
    """
    obs: –≤–µ–∫—Ç–æ—Ä (24,) = [HP1, INI1, ..., HP12, INI12]
    action: Discrete(6), 0..5 -> –∞—Ç–∞–∫–∞ RED –ø–æ–∑–∏—Ü–∏–π 1..6
    RED: –±—å—ë—Ç —Å–ª—É—á–∞–π–Ω–æ–≥–æ –∂–∏–≤–æ–≥–æ BLUE
    BLUE: —É–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è –∞–≥–µ–Ω—Ç–æ–º
    reward: +1 (BLUE win), -1 (RED win), 0 –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ
    """

    metadata = {"render_modes": []}

    def __init__(self, reward_win: float = 1.0, reward_loss: float = -1.0, reward_step: float = 0.0,
                 log_enabled: bool = False):
        super().__init__()
        self.reward_win = float(reward_win)
        self.reward_loss = float(reward_loss)
        self.reward_step = float(reward_step)
        self.log_enabled = bool(log_enabled)

        self.action_space = spaces.Discrete(6)
        low  = np.zeros(24, dtype=np.float32)
        high = np.array(sum([[MAX_HP, MAX_INIT] for _ in range(12)], []), dtype=np.float32)
        self.observation_space = spaces.Box(low=low, high=high, dtype=np.float32)

        self.rng = random.Random()
        self.combined = None
        self.round_no = None
        self.winner = None
        self.current_blue_attacker_pos = None

        self._pretty_events = []  # —Å—Ç—Ä–æ–∫–∏ –ª–æ–≥–æ–≤ (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ log_enabled=True)

    # --------- —É—Ç–∏–ª–∏—Ç—ã ---------
    def seed(self, seed=None):
        self.rng = random.Random(seed)

    def _alive(self, u): return u["–ó–¥–æ—Ä–æ–≤—å–µ"] > 0
    def _team_alive(self, team): return any(self._alive(u) and u["team"] == team for u in self.combined)
    def _unit_by_position(self, pos): return next((u for u in self.combined if u["position"] == pos), None)
    def _live_positions_of(self, team): return [u["position"] for u in self.combined if u["team"] == team and self._alive(u)]

    def _log(self, s: str):
        if self.log_enabled: self._pretty_events.append(s)

    def pop_pretty_events(self):
        out = self._pretty_events[:]
        self._pretty_events.clear()
        return out

    def _reset_state(self):
        self.combined = [u.copy() for u in (UNITS_RED + UNITS_BLUE)]
        for u in self.combined:
            u["–∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–∞"] = u["–∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–∞_–±–∞–∑–∞"]
        self.round_no = 1
        self.winner = None
        self.current_blue_attacker_pos = None
        self._log(f"–≠–ø–∏–∑–æ–¥ –Ω–∞—á–∞—Ç. –†–∞—É–Ω–¥ {self.round_no}.")

    def _candidates(self):
        return [u for u in self.combined if self._alive(u) and u["–∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–∞"] > 0]

    def _pop_next(self):
        cand = self._candidates()
        if not cand:
            return None
        self.rng.shuffle(cand)
        cand.sort(key=itemgetter("–∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–∞"), reverse=True)
        return cand[0]

    def _end_round_restore(self):
        for u in self.combined:
            u["–∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–∞"] = u["–∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–∞_–±–∞–∑–∞"] if self._alive(u) else 0
        self._log("–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–Ω–∏—Ü–∏–∞—Ç–∏–≤—ã. –ù–æ–≤—ã–π —Ä–∞—É–Ω–¥.")

    def _attack(self, attacker, target_pos):
        victim = self._unit_by_position(target_pos) if target_pos is not None else None
        if victim is not None and self._alive(victim):
            before = victim["–ó–¥–æ—Ä–æ–≤—å–µ"]
            victim["–ó–¥–æ—Ä–æ–≤—å–µ"] -= attacker["–£—Ä–æ–Ω"]
            after = victim["–ó–¥–æ—Ä–æ–≤—å–µ"]
            self._log(f"{attacker['team'].upper()} {attacker['–∏–º—è']}#{attacker['position']} ‚Üí "
                      f"{victim['team'].upper()} {victim['–∏–º—è']}#{victim['position']}: {attacker['–£—Ä–æ–Ω']} "
                      f"({before}‚Üí{max(0, after)})")
            if victim["–ó–¥–æ—Ä–æ–≤—å–µ"] <= 0:
                victim["–∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–∞"] = 0
                self._log(f"‚úñ {victim['team'].upper()} {victim['–∏–º—è']}#{victim['position']} –≤—ã–≤–µ–¥–µ–Ω –∏–∑ —Å—Ç—Ä–æ—è.")
        else:
            self._log(f"{attacker['team'].upper()} {attacker['–∏–º—è']}#{attacker['position']} –±—å—ë—Ç pos{target_pos}: —Ü–µ–ª–∏ –Ω–µ—Ç/–º–µ—Ä—Ç–≤–∞.")

    def _check_victory_after_hit(self):
        if not self._team_alive("blue"):
            self.winner = "red";  self._log("üèÜ –ü–æ–±–µ–¥–∞ RED!")
        elif not self._team_alive("red"):
            self.winner = "blue"; self._log("üèÜ –ü–æ–±–µ–¥–∞ BLUE!")

    def _advance_until_blue_turn(self):
        while self._team_alive("red") and self._team_alive("blue"):
            nxt = self._pop_next()
            if nxt is None:
                self._log(f"‚Äî –ö–æ–Ω–µ—Ü —Ä–∞—É–Ω–¥–∞ {self.round_no}.")
                self._end_round_restore()
                self.round_no += 1
                self._log(f"‚Äî –ù–∞—á–∞–ª–æ —Ä–∞—É–Ω–¥–∞ {self.round_no}.")
                continue

            if nxt["team"] == "blue":
                self.current_blue_attacker_pos = nxt["position"]
                self._log(f"–•–æ–¥ BLUE: {nxt['–∏–º—è']}#{nxt['position']} (–∏–Ω–∏—Ü {nxt['–∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–∞']}). –û–∂–∏–¥–∞–Ω–∏–µ –¥–µ–π—Å—Ç–≤–∏—è.")
                return True

            # RED —Ö–æ–¥–∏—Ç: —Å–ª—É—á–∞–π–Ω–∞—è –∂–∏–≤–∞—è —Å–∏–Ω—è—è —Ü–µ–ª—å
            nxt["–∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–∞"] = 0
            live_blue_positions = self._live_positions_of("blue")
            target_pos = self.rng.choice(live_blue_positions) if live_blue_positions else None
            self._log(f"RED —Ö–æ–¥: {nxt['–∏–º—è']}#{nxt['position']} ‚Üí —Å–ª—É—á–∞–π–Ω–∞—è —Ü–µ–ª—å pos{target_pos}.")
            self._attack(nxt, target_pos)
            self._check_victory_after_hit()
            if self.winner is not None:
                return False
        return False

    def _obs(self):
        vec = []
        for pos in RED_POSITIONS + BLUE_POSITIONS:
            u = self._unit_by_position(pos)
            vec.extend([float(max(0, u["–ó–¥–æ—Ä–æ–≤—å–µ"])), float(max(0, u["–∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–∞"]))])
        return np.array(vec, dtype=np.float32)

    # ----------------- API Gymnasium -----------------
    def reset(self, *, seed=None, options=None):
        if seed is not None:
            self.seed(seed)
        self._reset_state()
        self._advance_until_blue_turn()
        return self._obs(), {}

    def step(self, action):
        assert self.winner is None, "–≠–ø–∏–∑–æ–¥ –∑–∞–≤–µ—Ä—à—ë–Ω ‚Äî –≤—ã–∑–æ–≤–∏—Ç–µ reset()."
        if self.current_blue_attacker_pos is None:
            self._advance_until_blue_turn()
            if self.winner is not None:
                return self._obs(), (self.reward_win if self.winner == "blue" else self.reward_loss), True, False, {}

        # BLUE (–∞–≥–µ–Ω—Ç)
        target_pos = RED_POSITIONS[int(action)]
        attacker = self._unit_by_position(self.current_blue_attacker_pos)
        if attacker is not None and self._alive(attacker) and attacker["–∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–∞"] > 0:
            self._log(f"BLUE –¥–µ–π—Å—Ç–≤–∏–µ: {attacker['–∏–º—è']}#{attacker['position']} ‚Üí pos{target_pos}")
            attacker["–∏–Ω–∏—Ü–∏–∞—Ç–∏–≤–∞"] = 0
            self._attack(attacker, target_pos)
            self._check_victory_after_hit()

        if self.winner is None:
            self.current_blue_attacker_pos = None
            self._advance_until_blue_turn()

        if self.winner is None:
            reward, terminated = self.reward_step, False
        else:
            reward = self.reward_win if self.winner == "blue" else self.reward_loss
            terminated = True

        return self._obs(), reward, terminated, False, {}


# ============================================================
#                –û–ë–£–ß–ï–ù–ò–ï PPO + W&B –õ–û–ì–ò–†–û–í–ê–ù–ò–ï
# ============================================================
if __name__ == "__main__":
    from stable_baselines3 import PPO
    from stable_baselines3.common.env_util import make_vec_env
    from stable_baselines3.common.monitor import Monitor
    from stable_baselines3.common.callbacks import CallbackList, EvalCallback
    import wandb
    from wandb.integration.sb3 import WandbCallback

    # ----------- –ü–ê–†–ê–ú–ï–¢–†–´ -----------
    TOTAL_STEPS = 50_000
    N_ENVS = 8
    VISUALIZE_TEST = True     # ‚Üê –≤–∫–ª—é—á–∏—Ç—å/–≤—ã–∫–ª—é—á–∏—Ç—å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é –ø–æ –ª–æ–≥–∞–º –≤ –∫–æ–Ω—Ü–µ
    FRAME_DELAY = 0.28        # –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∫–∞–¥—Ä–∞–º–∏
    USE_COLOR = True

    # -------- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è W&B --------
    run = wandb.init(
        project="red-blue-battle",
        name=f"ppo-{TOTAL_STEPS//1000}k",
        config={
            "algo": "PPO",
            "total_timesteps": TOTAL_STEPS,
            "n_envs": N_ENVS,
            "n_steps": 1024,
            "batch_size": 2048,
            "gamma": 0.99,
            "gae_lambda": 0.95,
            "learning_rate": 3e-4,
            "clip_range": 0.2,
        },
        sync_tensorboard=True,
        save_code=True,
    )

    def make_env():
        return Monitor(BattleEnv(reward_win=1.0, reward_loss=-1.0, reward_step=0.0, log_enabled=False))

    vec_env = make_vec_env(make_env, n_envs=N_ENVS, seed=42, monitor_dir="./monitor")
    eval_env = Monitor(BattleEnv(log_enabled=False))

    model = PPO(
        policy="MlpPolicy",
        env=vec_env,
        verbose=1,
        n_steps=1024,
        batch_size=2048,
        gae_lambda=0.95,
        gamma=0.99,
        n_epochs=10,
        learning_rate=3e-4,
        clip_range=0.2,
        ent_coef=0.0,
        vf_coef=0.5,
        seed=42,
        tensorboard_log=f"./tb_logs/{run.id}",
    )

    wandb_cb = WandbCallback(
        gradient_save_freq=1000,
        model_save_path=f"./models/{run.id}",
        model_save_freq=10_000,
        verbose=2,
    )
    eval_cb = EvalCallback(
        eval_env,
        best_model_save_path=f"./models/{run.id}/best",
        log_path=f"./eval/{run.id}",
        eval_freq=10_000,
        n_eval_episodes=5,
        deterministic=True,
        render=False,
    )
    model.learn(total_timesteps=TOTAL_STEPS, callback=CallbackList([wandb_cb, eval_cb]))
    model.save("ppo_blue_vs_red")
    run.finish()

    # =======================================================
    #   –¢–ï–°–¢–û–í–´–ô –ü–†–û–ì–û–ù –° –õ–û–ì–ê–ú–ò (–∏ –æ–ø—Ü. –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–ï–ô)
    # =======================================================
    print("\n=== –¢–ï–°–¢–û–í–´–ô –ü–†–û–ì–û–ù –° –õ–û–ì–ê–ú–ò ===")
    test_env = BattleEnv(log_enabled=True)
    obs, info = test_env.reset(seed=123)

    all_logs = []
    all_logs += test_env.pop_pretty_events()

    done = False
    total_reward = 0.0
    step_i = 0
    while not done:
        step_i += 1
        action, _ = model.predict(obs, deterministic=True)
        target_pos = RED_POSITIONS[int(action)]
        chosen_line = f"[STEP {step_i}] –ê–≥–µ–Ω—Ç –≤—ã–±–∏—Ä–∞–µ—Ç action={int(action)} ‚Üí –∞—Ç–∞–∫–∞ RED pos{target_pos}"
        print("\n" + chosen_line)
        all_logs.append(chosen_line)

        obs, reward, terminated, truncated, info = test_env.step(action)
        total_reward += reward
        done = terminated or truncated

        new_lines = test_env.pop_pretty_events()
        all_logs += new_lines
        for line in new_lines:
            print(line)

    print("\n=== –≠–ü–ò–ó–û–î –ó–ê–í–ï–†–®–Å–ù ===")
    print("–ü–æ–±–µ–¥–∏—Ç–µ–ª—å:", test_env.winner.upper(), "| –°—É–º–º–∞—Ä–Ω–∞—è –Ω–∞–≥—Ä–∞–¥–∞:", total_reward)

    # -------------------------------
    #  –û–ü–¶–ò–û–ù–ê–õ–¨–ù–ê–Ø –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø
    # -------------------------------
    if VISUALIZE_TEST:
        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è ¬´—Ç–æ–ª—å–∫–æ –ø–æ –ª–æ–≥–∞–º¬ª
        import re, os, shutil, time

        ANSI = {
            "reset": "\033[0m",
            "bold": "\033[1m",
            "red": "\033[31m",
            "blue": "\033[34m",
            "yellow": "\033[33m",
        }

        def colorize(s, c=None):
            if not USE_COLOR or c not in ANSI: return s
            return f"{ANSI[c]}{s}{ANSI['reset']}"

        def clear_console():
            os.system("cls" if os.name == "nt" else "clear")

        def hp_bar(hp, max_hp=MAX_HP, width=14):
            hp = max(0, min(hp, max_hp))
            filled = int(round((hp / max_hp) * width))
            return "‚ñà" * filled + "‚ñë" * (width - filled)

        # –°–æ—Å—Ç–æ—è–Ω–∏–µ —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∏—Ä—É–µ–º –¢–û–õ–¨–ö–û –∏–∑ –ª–æ–≥–æ–≤: —Å—Ç–∞—Ä—Ç–æ–≤—ã–µ HP=60
        state = {u["position"]: {"team": u["team"], "name": u["–∏–º—è"], "hp": MAX_HP}
                 for u in (UNITS_RED + UNITS_BLUE)}

        # –†–µ–≥–µ–∫—Å –¥–ª—è —Å—Ç—Ä–æ–∫ —É–¥–∞—Ä–∞:   TEAM Name#pos ‚Üí TEAM Name#pos: dmg (before‚Üíafter)
        atk_re = re.compile(
            r'^(RED|BLUE)\s+([^\s#]+)#(\d+)\s+‚Üí\s+(RED|BLUE)\s+([^\s#]+)#(\d+):\s+(\d+)\s+\((\d+)‚Üí(\d+)\)'
        )
        kill_re = re.compile(r'^‚úñ\s+(RED|BLUE)\s+([^\s#]+)#(\d+)\s+–≤—ã–≤–µ–¥–µ–Ω –∏–∑ —Å—Ç—Ä–æ—è\.')
        victory_re = re.compile(r'^üèÜ –ü–æ–±–µ–¥–∞ (RED|BLUE)!')

        def board_snapshot():
            left = [state[p] for p in RED_POSITIONS]
            right = [state[p] for p in BLUE_POSITIONS]
            header = colorize("   RED (1‚Äì6)".ljust(50) + "BLUE (7‚Äì12)", "bold")
            lines = [header]
            for i in range(6):
                lu = left[i]; ru = right[i]
                ltxt = f"{colorize(lu['name'][:10].ljust(10), 'red')} [{hp_bar(lu['hp'])}] {str(lu['hp']).rjust(3)}hp"
                rtxt = f"{colorize(ru['name'][:10].ljust(10), 'blue')} [{hp_bar(ru['hp'])}] {str(ru['hp']).rjust(3)}hp"
                lines.append(f"{ltxt:<50} {rtxt}")
            return "\n".join(lines)

        def render_frame(banner):
            clear_console()
            term_w = shutil.get_terminal_size((100, 25)).columns
            sep = "‚îÄ" * min(term_w, 100)
            print(board_snapshot())
            print("\n" + sep)
            print(banner)
            print(sep)

        # –ü–æ—à–∞–≥–æ–≤–æ ¬´–ø—Ä–æ–∏–≥—Ä—ã–≤–∞–µ–º¬ª –ª–æ–≥–∏ –∏ –æ–±–Ω–æ–≤–ª—è–µ–º HP –ø–æ after-–∑–Ω–∞—á–µ–Ω–∏—è–º
        for line in all_logs:
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏—è HP –∏–∑ —É–¥–∞—Ä–∞
            m = atk_re.match(line)
            if m:
                # groups: 1 atk_team,2 atk_name,3 atk_pos,4 vic_team,5 vic_name,6 vic_pos,7 dmg,8 before,9 after
                vic_pos = int(m.group(6))
                after = int(m.group(9))
                if vic_pos in state:
                    state[vic_pos]["hp"] = after

                render_frame(colorize(line, "yellow"))
                time.sleep(FRAME_DELAY)
                continue

            # –£–±–∏–π—Å—Ç–≤–∞ ‚Äî –ø—Ä–æ—Å—Ç–æ –±–∞–Ω–Ω–µ—Ä (HP —É–∂–µ 0 –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–π —Å—Ç—Ä–æ–∫–∏ ¬´(before‚Üíafter)¬ª)
            if kill_re.match(line) or victory_re.match(line) or line.startswith("‚Äî ") or "–•–æ–¥ BLUE" in line or "RED —Ö–æ–¥" in line or line.startswith("[STEP"):
                render_frame(colorize(line, "yellow"))
                time.sleep(FRAME_DELAY/1.2)

        # —Ñ–∏–Ω–∞–ª—å–Ω–∞—è –ø–∞—É–∑–∞
        time.sleep(1.5)
